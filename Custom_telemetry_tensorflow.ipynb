{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f830e8cc-c060-4cc6-836d-20b08ab2e248",
   "metadata": {},
   "source": [
    "# Telemetry data using Custom TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4acc9f-18e5-4d7c-a0e7-d40b548a2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition, FeatureTypeEnum\n",
    "\n",
    "# # Initialize the S3 client\n",
    "# s3_client = boto3.resource('s3')\n",
    "\n",
    "# # Define the pipeline name\n",
    "# # pipeline_name = f\"telemetry-sagemaker-mlops-train-pipeline\"\n",
    "\n",
    "# # Initialize the SageMaker session\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# # Get the AWS region\n",
    "# region = sagemaker_session.boto_region_name\n",
    "\n",
    "# # Get the SageMaker execution role\n",
    "# role = sagemaker.get_execution_role()\n",
    "\n",
    "# # Initialize the Pipeline session\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "# # Get the default S3 bucket\n",
    "# default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "# Define the model package group name\n",
    "\n",
    "model_package_group_name = \"TF2-telemetry-engine\"  #Model name in model registry\n",
    "prefix = \"tf2-telemetry-engine-pipelines\"\n",
    "pipeline_name = \"TF2telemetryEnginePipeline\"  #SageMaker Pipeline name\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "492dc5d8-0d83-4539-91bf-93e306434124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip  install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb282bd3-b9fc-4ce2-88fa-e3385a57a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "tel_raw_dir = os.path.join(os.getcwd(), \"data/tel_raw\")\n",
    "os.makedirs(tel_raw_dir, exist_ok=True)\n",
    "\n",
    "fs_data = os.path.join(os.getcwd(), \"data/fs_data\")\n",
    "os.makedirs(fs_data, exist_ok=True)\n",
    "\n",
    "# Define the S3 URI for the input data\n",
    "# input_data_uri =\"s3://msil-ds/raw-data/cal_housing.tgz\"\n",
    "# s3 = boto3.client(\"s3\")\n",
    "# s3.download_file(\n",
    "#     \"msil-ds\", #bucket Name\n",
    "#     \"raw-data/cal_housing.tgz\",#prefix\n",
    "#     \"data/raw/cal_housing.tgz\",#local path\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6a48e8b-beb9-4f4e-b395-5d2ae850464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -zxf data/raw/cal_housing.tgz #extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e29f27-ee89-4384-a842-811d8653dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_uri = \"s3://msil-ds/raw-data/new_telemetry_data.csv\"\n",
    "# Define the S3 URI for the requirements file\n",
    "req_url = \"s3://msil-ds/raw-data/requirements.txt\"\n",
    "\n",
    "# Import necessary modules from SageMaker Workflow\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "# Define the processing instance count parameter\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "# Define the processing instance type parameter\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "# Define the training instance type parameter\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "# Define the model approval status parameter\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c665e48b-79c7-4907-9b42-98713de62169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifyrecord</th>\n",
       "      <th>Eventime</th>\n",
       "      <th>speed</th>\n",
       "      <th>engine_status</th>\n",
       "      <th>fuel_level</th>\n",
       "      <th>battery_voltage</th>\n",
       "      <th>tire_pressure</th>\n",
       "      <th>current_gear</th>\n",
       "      <th>odometer_reading</th>\n",
       "      <th>engine_temperature</th>\n",
       "      <th>coolant_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10-04-2024 00:00</td>\n",
       "      <td>108.53</td>\n",
       "      <td>0</td>\n",
       "      <td>53.03</td>\n",
       "      <td>11.95</td>\n",
       "      <td>33.97</td>\n",
       "      <td>0</td>\n",
       "      <td>43323.02</td>\n",
       "      <td>110.87</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>11-04-2024 00:00</td>\n",
       "      <td>68.59</td>\n",
       "      <td>1</td>\n",
       "      <td>12.21</td>\n",
       "      <td>12.39</td>\n",
       "      <td>29.86</td>\n",
       "      <td>0</td>\n",
       "      <td>45975.75</td>\n",
       "      <td>118.53</td>\n",
       "      <td>97.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>12-04-2024 00:00</td>\n",
       "      <td>118.31</td>\n",
       "      <td>1</td>\n",
       "      <td>87.17</td>\n",
       "      <td>12.81</td>\n",
       "      <td>35.19</td>\n",
       "      <td>3</td>\n",
       "      <td>29510.29</td>\n",
       "      <td>113.63</td>\n",
       "      <td>49.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>13-04-2024 00:00</td>\n",
       "      <td>110.32</td>\n",
       "      <td>1</td>\n",
       "      <td>92.09</td>\n",
       "      <td>13.43</td>\n",
       "      <td>30.54</td>\n",
       "      <td>0</td>\n",
       "      <td>10258.51</td>\n",
       "      <td>101.41</td>\n",
       "      <td>16.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>14-04-2024 00:00</td>\n",
       "      <td>110.94</td>\n",
       "      <td>1</td>\n",
       "      <td>13.08</td>\n",
       "      <td>12.34</td>\n",
       "      <td>35.64</td>\n",
       "      <td>3</td>\n",
       "      <td>77187.78</td>\n",
       "      <td>86.43</td>\n",
       "      <td>21.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifyrecord          Eventime   speed  engine_status  fuel_level  \\\n",
       "0             100  10-04-2024 00:00  108.53              0       53.03   \n",
       "1             101  11-04-2024 00:00   68.59              1       12.21   \n",
       "2             102  12-04-2024 00:00  118.31              1       87.17   \n",
       "3             103  13-04-2024 00:00  110.32              1       92.09   \n",
       "4             104  14-04-2024 00:00  110.94              1       13.08   \n",
       "\n",
       "   battery_voltage  tire_pressure  current_gear  odometer_reading  \\\n",
       "0            11.95          33.97             0          43323.02   \n",
       "1            12.39          29.86             0          45975.75   \n",
       "2            12.81          35.19             3          29510.29   \n",
       "3            13.43          30.54             0          10258.51   \n",
       "4            12.34          35.64             3          77187.78   \n",
       "\n",
       "   engine_temperature  coolant_level  \n",
       "0              110.87           7.89  \n",
       "1              118.53          97.97  \n",
       "2              113.63          49.50  \n",
       "3              101.41          16.79  \n",
       "4               86.43          21.78  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "telemetry_df = pd.read_csv(input_data_uri)\n",
    "telemetry_df[\"engine_status\"] = telemetry_df['engine_status'].map({'ON': 1, 'OFF': 0})\n",
    "telemetry_df[\"current_gear\"] = telemetry_df['current_gear'].map({'N': 0, 'R': 1,'P':2,'D':3})\n",
    "\n",
    "telemetry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f709a8ab-6b8b-4f1f-ac4e-6f58a380c4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['identifyrecord', 'Eventime', 'speed', 'engine_status', 'fuel_level',\n",
       "       'battery_voltage', 'tire_pressure', 'current_gear', 'odometer_reading',\n",
       "       'engine_temperature', 'coolant_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telemetry_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d5f8596-ecae-41d3-8431-ffa9e80ea082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-south-1-955658629586/tf2-telemetry-engine-pipelines/data/tel_raw\n",
      "Index(['speed', 'engine_status', 'fuel_level', 'battery_voltage',\n",
      "       'tire_pressure', 'current_gear', 'odometer_reading', 'coolant_level'],\n",
      "      dtype='object') Index(['engine_temperature'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "X = telemetry_df[\n",
    "    ['speed', 'engine_status', 'fuel_level',\n",
    "       'battery_voltage', 'tire_pressure', 'current_gear', 'odometer_reading', 'coolant_level']\n",
    "]\n",
    "Y = telemetry_df[[\"engine_temperature\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "np.save(os.path.join(tel_raw_dir, \"x_train.npy\"), x_train.to_numpy())\n",
    "np.save(os.path.join(tel_raw_dir, \"x_test.npy\"), x_test.to_numpy())\n",
    "np.save(os.path.join(tel_raw_dir, \"y_train.npy\"), y_train.to_numpy())\n",
    "np.save(os.path.join(tel_raw_dir, \"y_test.npy\"), y_test.to_numpy())\n",
    "rawdata_s3_prefix = \"{}/data/tel_raw\".format(prefix)\n",
    "raw_s3 = sagemaker_session.upload_data(path=\"./data/tel_raw/\", key_prefix=rawdata_s3_prefix)\n",
    "print(raw_s3)\n",
    "print(x_train.columns,y_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1690506e-fe29-41fc-9d5e-0dfcc497f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "# raw input data\n",
    "input_data = ParameterString(name=\"InputData\", default_value=raw_s3)\n",
    "\n",
    "# training step parameters\n",
    "training_epochs = ParameterString(name=\"TrainingEpochs\", default_value=\"100\")\n",
    "\n",
    "# model performance step parameters\n",
    "accuracy_mse_threshold = ParameterFloat(name=\"AccuracyMseThreshold\", default_value=0.75)\n",
    "\n",
    "# Inference step parameters\n",
    "endpoint_instance_type = ParameterString(name=\"EndpointInstanceType\", default_value=\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f478e-8c65-4d61-9da5-879d2ca1273c",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Processing</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3bd2204-5fca-4732-9b97-d71f035c30e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# Define the SKLearn framework version\n",
    "framework_version = \"1.2-1\"\n",
    "\n",
    "# Initialize the SKLearn processor\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"tf2-telemetry-engine-processing-job\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Define the processor arguments for running the SKLearn processor\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data, \n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        ),\n",
    "        ProcessingInput(source=req_url, destination=\"/opt/ml/processing/requirement/\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\", \n",
    "            source=\"/opt/ml/processing/train\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\", \n",
    "            source=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    code=\"telemetry_tensorflow/preprocess.py\",\n",
    ")\n",
    "\n",
    "# Define the processing step for the pipeline\n",
    "step_process = ProcessingStep(\n",
    "    name=\"TF-Preprocess-telemetry-Data\",\n",
    "    step_args=processor_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb30a9-2fa3-4a3e-bee5-5ffc80c88a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fd99538-dca6-4c9e-b76a-81a575148ef4",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">feature store</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0859a95-a89b-4083-873a-02b62719e703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Store tensorflow-telemetry-featuregroup-TTF2 already present, skipping creation part\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "import time\n",
    "import uuid\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition, FeatureTypeEnum\n",
    "import pandas as pd\n",
    "\n",
    "# Constants and configuration\n",
    "record_identifier_feature_name = \"identifyrecord\"\n",
    "event_time_feature_name = \"Eventime\"\n",
    "input_data_uri = \"s3://msil-ds/raw-data/new_telemetry_data.csv\"  # Make sure input_data_uri is defined earlier in your script\n",
    "\n",
    "# Read the data and infer schema\n",
    "col_def_after_processing = [{'name': 'speed', 'type':  'float64'},\n",
    " {'name': 'fuel_level', 'type':  'float64'},\n",
    " {'name': 'battery_voltage', 'type':  'float64'},\n",
    " {'name': 'tire_pressure', 'type':  'float64'},\n",
    " {'name': 'odometer_reading', 'type':  'float64'},\n",
    " {'name': 'coolant_level', 'type':  'float64'},\n",
    "                            \n",
    " {'name': 'engine_status', 'type':  'float64'},\n",
    " {'name': 'current_gear', 'type':  'float64'},\n",
    " {'name': 'identifyrecord', 'type': 'int64'},\n",
    " {'name': 'Eventime', 'type':  'object'},\n",
    "{'name': 'engine_temperature', 'type':  'float64'}]\n",
    "column_names = [col['name'] for col in col_def_after_processing]\n",
    "column_types = {col['name']: col['type'] for col in col_def_after_processing}\n",
    "\n",
    "# Create an empty DataFrame with the specified column names\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Convert data types of DataFrame columns\n",
    "for col, dtype in column_types.items():\n",
    "    df[col] = df[col].astype(dtype)\n",
    "\n",
    "\n",
    "# Define feature group name\n",
    "feature_group_name = \"tensorflow-telemetry-featuregroup-TTF2\"\n",
    "# feature_group_name = f\"telemetry-feature-group-{str(uuid.uuid4())[:8]}\"  # Alternatively generate a unique name\n",
    "\n",
    "# Initialize the SageMaker FeatureGroup\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name, \n",
    "    sagemaker_session=sagemaker.Session()  # Ensure sagemaker_session is defined earlier\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Check if the feature group already exists\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status == \"Created\":\n",
    "        print(f\"Feature Store {feature_group_name} already present, skipping creation part\")\n",
    "except Exception as e:\n",
    "    print(f\"Feature group not found(Hence Creating Another one) : {e}\")\n",
    "    current_time_sec = int(round(time.time()))\n",
    "    \n",
    "    # Load feature definitions and create feature group\n",
    "    feature_group.load_feature_definitions(data_frame=df)\n",
    "    feature_store_offline_s3_uri = 's3://' + bucket  # Ensure default_bucket is defined earlier\n",
    "    feature_group.create(\n",
    "        s3_uri=feature_store_offline_s3_uri,\n",
    "        record_identifier_name=record_identifier_feature_name,\n",
    "        event_time_feature_name=event_time_feature_name,\n",
    "        role_arn=sagemaker.get_execution_role(),  # Ensure role is defined earlier\n",
    "        enable_online_store=True\n",
    "    )\n",
    "    \n",
    "    # Wait for the feature group to be created\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group to be created...\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f5c4495-d816-4b24-b541-54b42d4fc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pd.DataFrame(np.load(os.path.join(\"x_train.npy\")),  columns = ['longitude', 'latitude', 'housingMedianAge', 'totalRooms',\n",
    "#        'totalBedrooms', 'population', 'households', 'medianIncome'])\n",
    "# x_train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae501cb8-3711-4d9e-864b-9406d1ac1a38",
   "metadata": {},
   "source": [
    "# Feature store data INGEST, FETCH using Athena Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f6ca765-2833-42e7-b486-7e28fd2778a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor \n",
    "\n",
    "# Define the SKLearn framework version\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"tf2-telemetry-engine-processing-job\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "\n",
    "# Run the SKLearn processor with the specified inputs\n",
    "fs_arg = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/train/\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=req_url, \n",
    "            destination=\"/opt/ml/processing/input/\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_fs\", \n",
    "            source=\"/opt/ml/processing/train_fs\"\n",
    "        )],\n",
    "    code=\"telemetry_tensorflow/testfeaturestore.py\",\n",
    ") \n",
    "\n",
    "# Define the processing step for the pipeline\n",
    "step_feature = ProcessingStep(\n",
    "    name=\"TF-Featurestore-telemetry-ingestion-fetch\",\n",
    "    step_args=fs_arg,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d52fb3-07d8-476f-8444-9de0776a960a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55add29-beee-402f-a908-7ca370922b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e1fed38-1a32-46f9-9464-e565ea05951c",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Training</span>\n",
    "### Trainining input from Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efc257c9-86de-46c8-8893-54669ebf249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity_query = feature_group.athena_query()\n",
    "# identity_table = identity_query.table_name\n",
    "\n",
    "# query_string = 'SELECT longitude,\tlatitude,\thousingMedianAge,\ttotalRooms,\ttotalBedrooms,\tpopulation,\thouseholds,\tmedianIncome  FROM \"'+identity_table+'\" '\n",
    "\n",
    "# # run Athena query. The output is loaded to a Pandas dataframe.\n",
    "# dataset = pd.DataFrame()\n",
    "# identity_query.run(query_string=query_string, output_location='s3://'+bucket+'/query_results/')\n",
    "# identity_query.wait()\n",
    "# x_train = identity_query.as_dataframe()\n",
    "# x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f096b6a-b771-42a1-a829-725d9aa83978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_string = f'SELECT target  FROM \"{identity_table}\"'\n",
    "# identity_query.run(query_string=query_string, output_location = f's3://{bucket}/query_results/')\n",
    "# identity_query.wait()\n",
    "# y_train = identity_query.as_dataframe()\n",
    "# y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "032d213d-34b5-4013-8989-8a74b8b128fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(os.path.join(fs_data, \"x_train.npy\"), x_train)\n",
    "# np.save(os.path.join(fs_data, \"y_train.npy\"), y_train)\n",
    "# fsdata_s3_prefix = \"{}/data/fs_data\".format(prefix)\n",
    "# fs_raw_s3 = sagemaker_session.upload_data(path=\"./data/fs_data/\", key_prefix=fsdata_s3_prefix)\n",
    "# print(fs_raw_s3)\n",
    "# feature_store_data = ParameterString(name=\"InputData\", default_value=fs_raw_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ee3a0b5-485c-4a64-b737-61e53d47ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training with columnar input, the algorithm assumes that the target variable (label) is the first column.\n",
    "# For inference, the algorithm assumes that the input has no label column.\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "import time\n",
    "\n",
    "# Where to store the trained model\n",
    "model_path = f\"s3://{bucket}/{prefix}/model/\"\n",
    "\n",
    "hyperparameters = {\"epochs\": 100}\n",
    "tensorflow_version = \"2.11.0\"\n",
    "python_version = \"py39\"\n",
    "\n",
    "tf2_estimator = TensorFlow(\n",
    "    source_dir=\"telemetry_tensorflow\",\n",
    "    entry_point=\"train.py\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    framework_version=tensorflow_version,\n",
    "    role=role,\n",
    "    base_job_name=\"tf2-telemetry-engine-train\",\n",
    "    output_path=model_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    py_version=python_version,\n",
    ")\n",
    "\n",
    "# Use the tf2_estimator in a Sagemaker pipelines ProcessingStep.\n",
    "# NOTE how the input to the training job directly references the output of the previous step.\n",
    "step_train = TrainingStep(\n",
    "    name=\"TF-Training-telemetry-Model\",\n",
    "    estimator=tf2_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_feature.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train_fs\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd0157-34a0-479e-b5cc-a2676f7d6300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e20961f-b0a6-44fb-b967-c2a08a72b138",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Evaluation</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be1309be-31fa-4e8e-9911-935209e1794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "# Create SKLearnProcessor object.\n",
    "# The object contains information about what container to use, what instance type etc.\n",
    "evaluate_model_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"tf2-telemetry-engine-evaluate\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Create a PropertyFile\n",
    "# A PropertyFile is used to be able to reference outputs from a processing step, for instance to use in a condition step.\n",
    "# For more information, visit https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# Use the evaluate_model_processor in a Sagemaker pipelines ProcessingStep.\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"TF-Evaluate-telemetry-Model\",\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"telemetry_tensorflow/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1f749-f35a-4956-9c3a-1e1df1d70d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7ab8fc7-d238-4f5f-ab06-5dc94e493f66",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Model Registry</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e6088ba-e33e-4796-b546-3d84ce62bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker import Model\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "# Initialize the Model with the top model S3 URI from the tuning step\n",
    "# model = Model(\n",
    "#     model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#     sagemaker_session=pipeline_session,\n",
    "#     role=role,\n",
    "# )\n",
    "\n",
    "# Define model metrics using the evaluation results from the evaluation step\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Register the model with specified parameters\n",
    "step_register = RegisterModel(\n",
    "    name=\"TF-Register-telemetry-Model\",\n",
    "    estimator=tf2_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86cc10-5909-4b33-9a9b-8ee0521cc309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a56aae3-c4a6-43ad-b9da-d12a95e17427",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Register model on condition</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce31e345-35d1-4b47-aa8e-b783b1f64331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Define the RMSE score threshold\n",
    "mse_score_threshold = 140\n",
    "\n",
    "# Define the condition for checking if RMSE score is less than or equal to the threshold\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\"\n",
    "    ),\n",
    "    right=mse_score_threshold\n",
    ")\n",
    "\n",
    "# Define the condition step\n",
    "step_cond = ConditionStep(\n",
    "    name=\"TF-MSE-telemetry-check\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],  # Register the model if condition is true\n",
    "    else_steps=[],  # No else steps defined\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "515252a9-ba8b-4178-ac98-b39a5a61ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Creating pipeline flow\n",
    "pipeline_name = \"NEW-Tensorflow-telemetry-sagemaker-pipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        mse_score_threshold,\n",
    "    ],\n",
    "    steps=[step_process,step_feature, step_train, step_eval, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ffdd07a-3840-4028-b8fc-6efc0e9f47e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'ProcessingInstanceCount',\n",
       "   'Type': 'Integer',\n",
       "   'DefaultValue': 1},\n",
       "  {'Name': 'ProcessingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.large'},\n",
       "  {'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.large'},\n",
       "  {'Name': 'ModelApprovalStatus',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'PendingManualApproval'},\n",
       "  {'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-ap-south-1-955658629586/tf2-telemetry-engine-pipelines/data/tel_raw'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'TF-Preprocess-telemetry-Data',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '720646828776.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocess.py']},\n",
       "    'RoleArn': 'arn:aws:iam::955658629586:role/service-role/AmazonSageMaker-ExecutionRole-20240517T103137',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://msil-ds/raw-data/requirements.txt',\n",
       "       'LocalPath': '/opt/ml/processing/requirement/',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-ap-south-1-955658629586/NEW-Tensorflow-telemetry-sagemaker-pipeline/code/d0a2614394c673a464f67106aafb6b68/preprocess.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3:/',\n",
       "           'sagemaker-ap-south-1-955658629586',\n",
       "           'NEW-Tensorflow-telemetry-sagemaker-pipeline',\n",
       "           {'Get': 'Execution.PipelineExecutionId'},\n",
       "           'TF-Preprocess-telemetry-Data',\n",
       "           'output',\n",
       "           'train']}},\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3:/',\n",
       "           'sagemaker-ap-south-1-955658629586',\n",
       "           'NEW-Tensorflow-telemetry-sagemaker-pipeline',\n",
       "           {'Get': 'Execution.PipelineExecutionId'},\n",
       "           'TF-Preprocess-telemetry-Data',\n",
       "           'output',\n",
       "           'test']}},\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'TF-Featurestore-telemetry-ingestion-fetch',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '720646828776.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/testfeaturestore.py']},\n",
       "    'RoleArn': 'arn:aws:iam::955658629586:role/service-role/AmazonSageMaker-ExecutionRole-20240517T103137',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.TF-Preprocess-telemetry-Data.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/train/',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://msil-ds/raw-data/requirements.txt',\n",
       "       'LocalPath': '/opt/ml/processing/input/',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-ap-south-1-955658629586/NEW-Tensorflow-telemetry-sagemaker-pipeline/code/cbab2e610ca8642e76db939431fd6b35/testfeaturestore.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_fs',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3:/',\n",
       "           'sagemaker-ap-south-1-955658629586',\n",
       "           'NEW-Tensorflow-telemetry-sagemaker-pipeline',\n",
       "           {'Get': 'Execution.PipelineExecutionId'},\n",
       "           'TF-Featurestore-telemetry-ingestion-fetch',\n",
       "           'output',\n",
       "           'train_fs']}},\n",
       "        'LocalPath': '/opt/ml/processing/train_fs',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'TF-Training-telemetry-Model',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '763104351884.dkr.ecr.ap-south-1.amazonaws.com/tensorflow-training:2.11.0-cpu-py39',\n",
       "     'EnableSageMakerMetricsTimeSeries': True},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-ap-south-1-955658629586/tf2-telemetry-engine-pipelines/model/'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'VolumeSizeInGB': 30,\n",
       "     'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.m5.large'},\n",
       "    'RoleArn': 'arn:aws:iam::955658629586:role/service-role/AmazonSageMaker-ExecutionRole-20240517T103137',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.TF-Featurestore-telemetry-ingestion-fetch.ProcessingOutputConfig.Outputs['train_fs'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'train'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.TF-Preprocess-telemetry-Data.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'test'}],\n",
       "    'HyperParameters': {'epochs': '100',\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-ap-south-1-955658629586/TF-Training-telemetry-Model-59bfaba94478a6d7bb54e353e1b0b8e8/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"train.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"ap-south-1\"',\n",
       "     'model_dir': '\"s3://sagemaker-ap-south-1-955658629586/tf2-telemetry-engine-pipelines/model/TF-Training-telemetry-Model-59bfaba94478a6d7bb54e353e1b0b8e8/model\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-ap-south-1-955658629586/tf2-telemetry-engine-pipelines/model/',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-ap-south-1-955658629586/tf2-telemetry-engine-pipelines/model/',\n",
       "     'DisableProfiler': False}}},\n",
       "  {'Name': 'TF-Evaluate-telemetry-Model',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.large',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '720646828776.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluate.py']},\n",
       "    'RoleArn': 'arn:aws:iam::955658629586:role/service-role/AmazonSageMaker-ExecutionRole-20240517T103137',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.TF-Training-telemetry-Model.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.TF-Preprocess-telemetry-Data.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-ap-south-1-955658629586/TF-Evaluate-telemetry-Model-8b9445ec248f86c0d71ea792a6d8ee86/input/code/evaluate.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-ap-south-1-955658629586/TF-Evaluate-telemetry-Model-8b9445ec248f86c0d71ea792a6d8ee86/output/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'TF-MSE-telemetry-check',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'LessThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.TF-Evaluate-telemetry-Model.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'regression_metrics.mse.value'}},\n",
       "      'RightValue': 140}],\n",
       "    'IfSteps': [{'Name': 'TF-Register-telemetry-Model-RegisterModel',\n",
       "      'Type': 'RegisterModel',\n",
       "      'Arguments': {'ModelPackageGroupName': 'TF2-telemetry-engine',\n",
       "       'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "          'S3Uri': 's3://sagemaker-ap-south-1-955658629586/TF-Evaluate-telemetry-Model-8b9445ec248f86c0d71ea792a6d8ee86/output/evaluation/evaluation.json'}},\n",
       "        'Bias': {},\n",
       "        'Explainability': {}},\n",
       "       'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.ap-south-1.amazonaws.com/tensorflow-inference:2.11.0-cpu',\n",
       "          'ModelDataUrl': {'Get': 'Steps.TF-Training-telemetry-Model.ModelArtifacts.S3ModelArtifacts'}}],\n",
       "        'SupportedContentTypes': ['text/csv'],\n",
       "        'SupportedResponseMIMETypes': ['text/csv'],\n",
       "        'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large',\n",
       "         'ml.m5.xlarge'],\n",
       "        'SupportedTransformInstanceTypes': ['ml.m5.xlarge']},\n",
       "       'ModelApprovalStatus': 'PendingManualApproval',\n",
       "       'SkipModelValidation': 'None'}}],\n",
       "    'ElseSteps': []}}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5c37ae4-f815-4798-8125-a6352a782f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:ap-south-1:955658629586:pipeline/NEW-Tensorflow-telemetry-sagemaker-pipeline/execution/vf1yz6cknv0m', sagemaker_session=<sagemaker.session.Session object at 0x7f6fab568100>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b18d5257-4c98-4d75-a48d-50352c4eab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample to fetch Data from feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba38cd74-da4a-4a5c-b2a2-fdec14ef06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the record from the Feature Store\n",
    "#Online Store: When using the get_record method or querying via the FeatureGroup's online methods, the data is being accessed from the online store.\n",
    "#Offline Store: When querying data through Athena or reading from the S3 bucket where the offline store data is stored, the data is coming from the offline store.\n",
    "\n",
    "# response = feature_group.get_record(\n",
    "#     record_identifier_value_as_string=\"2\"\n",
    "# )\n",
    "\n",
    "# # Print the fetched record\n",
    "# pd.DataFrame(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc352c3-37c5-43c3-aae7-4b63090c99e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
